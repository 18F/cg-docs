---
menu:
  main:
    parent: apps
title: S3 Access
---

For applications which prefer to store their content in S3, Cloud.gov provides a service which allows direct access

## Enable S3 for the Application

First make sure your account has S3 available to it: `cf marketplace`.  If you don't see the s3 service listed, #cloud-gov-support on Slack can enable your account.

Once you have confirmed S3 is available, we will want to start the service and assign it to your application.  If you just want S3, we can spin up a micro app just to allow S3 access.

```bash
cf create-service <APP_NAME>-s3 s3 basic
cf bind-service <APP_NAME> <APP_NAME>-s3
cf restage <APP_NAME>
```

This will put the S3 access information in your apps ENVIRONMENT variables, which you can check with `cf env <APP_NAME>`.

## Getting S3 Bucket Credentials
Typically to interact with S3 the [AWS Command Line Interface](https://aws.amazon.com/cli/) is used.  The Amazon CLI needs the following ENVIRONMENT variables:
 1. AWS_ACCESS_KEY_ID 
 2. AWS_SECRET_ACCESS_KEY 
 
You can download the [jq](https://stedolan.github.io/jq/) tool to get this information by pasting the below (or just run `cf env` and cut and paste from it):

```bash
export CF_CREDENTIALS=$(cf env cfs3) 
export AWS_ACCESS_KEY_ID=`echo "${CF_CREDENTIALS}" | tail -n +5 | jq -r .VCAP_SERVICES.s3[].credentials.access_key_id 2>/dev/null`
export AWS_SECRET_ACCESS_KEY=`echo "${CF_CREDENTIALS}" | tail -n +5 | jq -r .VCAP_SERVICES.s3[].credentials.secret_access_key 2>/dev/null`
export BUCKET_NAME=`echo "${CF_CREDENTIALS}" | tail -n +5 | jq -r .VCAP_SERVICES.s3[].credentials.bucket 2>/dev/null`
```

This will set the AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY and BUCKET_NAME, enabling the CLI tool to add, download and modify files as needed:

```bash
# Copy a file
aws s3 cp ./mylocalfile s3://${BUCKET_NAME}/

# Download a file
aws s3 cp s3://${BUCKET_NAME}/mys3file .

# See all files
aws s3 ls s3://${BUCKET_NAME}
```

### Allowing Access from Other Applications
If users wish to access their S3 buckets from outside of their Cloud.gov application then set a CORS policy, which loosens security restrictions.  This is *NOT* recommended, however with a sufficiently restricted list of sites and methods can be safe:

```bash
# Adjust CORS AllowedOrigins to known locations such as a IP address
cat << EOF > cors.json
{
  "CORSRules": [
    {
      "AllowedOrigins": ["YOUR.OTHER.APP.IP"],
      "AllowedHeaders": ["*"],
      "AllowedMethods": ["HEAD", "GET"],
      "ExposeHeaders": ["ETag"]
    }
  ]
}
EOF

# Upload the CORS policy to the bucket
aws s3api put-bucket-cors --bucket $BUCKET_NAME --cors-configuration file://cors.json
```

Additional method types above and beyond HEAD and GET, such as PUT, POST, DELETE can be added above as needed.

### Backup and Retention
By default, S3 data will stay where it is until `cf delete-service` is run on the `<APP_NAME>-s3` service.  This however is not a substitue for backups, and provides no protection from users accidentally deleting the contents.  

You can implement a backup scheme by storing your buckets under /data/year/month/day and keeping multiple copies in S3, using the aws cli. A Cloud.gov space can be created by your Organization Admin called backups, where the process above may be ran again to create "backup" buckets. 

# Glacier Backups for Long Term Data Retention
Amazon can automatically move your older data to S3.  Since S3 is just an Amazon service, we can have it back up to Glacier.  The following script will automatically move our old data from S3 to Glacier for long term data storage:

```bash
# Backup 
cat << EOF > backup.json
{
  "Rules": [
    {
      "ID": "Move to Glacier after sixty days (objects in data/)",
      "Prefix": "data/2016/",
      "Status": "Enabled",
      "Transition": {
        "Days": 60,
        "StorageClass": "GLACIER"
      }
    },
    {
      "Expiration": {
        "Date": "2017-01-01T00:00:00.000Z"
      },
      "ID": "Delete 2015 logs in 2017.",
      "Prefix": "data/2015/",
      "Status": "Enabled"
    }
  ]
}

aws s3api put-bucket-lifecycle --bucket my-bucket --lifecycle-configuration file://backup.json

```

Be careful when using this to store frequently used files in Glacier, as although it costs less to store them, *the cost to restore them is much higher*.  If data is frequently used, keep it in S3.

















































